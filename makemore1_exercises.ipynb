{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5131a247-d240-42bd-926b-5aba9ed24082",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d570098-46f8-473f-8117-31415848a9ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## E01\n",
    "\n",
    "Train a trigram language model, i.e. take two characters as an input to predict the 3rd one. Feel free to use either counting or a neural net. Evaluate the loss; Did it improve over a bigram model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3325ca-97e6-4827-8e82-26b0de3b04f5",
   "metadata": {},
   "source": [
    "### Count Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78ee82df-19b7-45e2-bb1c-df0ad36bea5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "words = open('names.txt', 'r').read().splitlines()\n",
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63cdc6d-a903-4d6e-9b50-f69c401c70f2",
   "metadata": {},
   "source": [
    "Arrange counts as (27, 27, 27) tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33114ca1-d27c-4c04-b04f-30ae731aa1f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = torch.zeros((27, 27, 27), dtype=torch.int32)\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "      ix1 = stoi[ch1]\n",
    "      ix2 = stoi[ch2]\n",
    "      ix3 = stoi[ch3]\n",
    "      #print('<', ch1, ix1,'>, <', ch2, ix2,'>, <', ch3, ix3, '>')\n",
    "      N[ix1, ix2, ix3] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f90880-ca8e-4308-b74e-57732efa9a17",
   "metadata": {},
   "source": [
    "Checking probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6be22e83-121d-4564-bc08-600a267a4d57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 'l')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = N[0, 1].float()\n",
    "p = p / p.sum()\n",
    "p\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "ix, itos[ix]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9ba34-bd9f-48ad-95cd-8ac98de871b2",
   "metadata": {},
   "source": [
    "Constructing probability matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "346a59b1-bb82-4fda-8a11-be92af4f4619",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = (N+1).float()\n",
    "P /= P.sum(2, keepdim=True)\n",
    "assert P[0, 0].sum() == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b663a97-8cc7-4a5a-b4e7-6ed29b7550bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([27, 27, 27])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865b7fd4-637f-4a65-8d7e-4977d6913f54",
   "metadata": {},
   "source": [
    "Sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b458b12-3e3f-4228-8dbf-73561cad4f55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "junide.\n",
      "ilyasid.\n",
      "prelay.\n",
      "ocin.\n",
      "fairritoper.\n",
      "sathen.\n",
      "dannaaryanileniassibduinrwin.\n",
      "lessiyanayla.\n",
      "te.\n",
      "farmumthyfortumj.\n",
      "ponn.\n",
      "zena.\n",
      "jaylicore.\n",
      "ya.\n",
      "zoffra.\n",
      "jamilyn.\n",
      "fmouis.\n",
      "yah.\n",
      "wanaasnhavi.\n",
      "honszxhddion.\n"
     ]
    }
   ],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(20):\n",
    "  out = []\n",
    "  # two starting chars\n",
    "  ix1 = 0\n",
    "  ix2 = 0\n",
    "  while True:\n",
    "      p = P[ix1, ix2] # prob vector of (ix1, ix2)\n",
    "      \n",
    "      # move chars along until we hit 0\n",
    "      ix1 = ix2\n",
    "      ix2 = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
    "      out.append(itos[ix2])\n",
    "      if ix2 == 0:\n",
    "          break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2494babf-e824-4bfc-81bb-bf4b6f9ddda7",
   "metadata": {},
   "source": [
    "Calculate loss which is negative log likelihood:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f23ba696-79b1-4ef6-9ea4-8d03c6cb4045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_lh=tensor(-410414.9688)\n",
      "nll=tensor(410414.9688)\n",
      "2.092747449874878\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "log_lh = 0.0\n",
    "for w in words:\n",
    "    chs = ['.'] + list(w) + ['.']\n",
    "    for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "        ix1 = stoi[ch1]\n",
    "        ix2 = stoi[ch2]\n",
    "        ix3 = stoi[ch3]\n",
    "        \n",
    "        prob = P[ix1, ix2, ix3]\n",
    "        logprob = torch.log(prob)\n",
    "        log_lh += logprob\n",
    "        n += 1\n",
    "        #print(f'{ch1}{ch2}: {prob:.4f} {logprob:.4f}')\n",
    "        \n",
    "print(f'{log_lh=}')\n",
    "nll= - log_lh\n",
    "print(f'{nll=}')\n",
    "print(f'{nll/n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d578b-a853-4d50-b203-daae546698b7",
   "metadata": {},
   "source": [
    "**Loss is \\~2 which is lower than bigram example of \\~2.4**\n",
    "\n",
    "*\"What letter comes next after `.a`?\"* is more precise than *\"What letter comes next after `a`?\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7535166b-1279-402f-9bd1-95ac792d2468",
   "metadata": {},
   "source": [
    "### NN Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8978a59e-edc8-4543-b839-b317816962db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0e3308-6d5c-455d-97e9-753032b5d15d",
   "metadata": {},
   "source": [
    "Create training set of trigrams, packing 1st and 2nd char as inputs and 3rd char as output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97eb02a5-4564-46a7-888b-486c76fba33a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".[5], e[5], m[13]\n",
      "e[13], m[13], m[13]\n",
      "m[13], m[13], a[1]\n",
      "m[1], a[1], .[0]\n",
      "number of examples:  8\n"
     ]
    }
   ],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words[:1]:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    xs.append((stoi[ch1], stoi[ch2]))\n",
    "    ys.append(stoi[ch3])\n",
    "    print(f'{ch1}[{stoi[ch2]}], {ch2}[{stoi[ch2]}], {ch3}[{stoi[ch3]}]')\n",
    "\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "num = xs.nelement()\n",
    "print('number of examples: ', num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a581cdb-f7f0-4545-bf12-ae3c17ec463d",
   "metadata": {},
   "source": [
    "One-hot encoding of examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb9d4d21-912e-46cd-92d3-0a680f1ab830",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0],\n",
      "         [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, torch.Size([4, 2, 27]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc = F.one_hot(xs, num_classes=27)\n",
    "print(xenc), xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4bdeec0-dd2d-4bc5-8834-22e9ed8ecc2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 2]), torch.Size([4]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape, ys.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bed1ef2-36b7-42e1-9e9c-63eab6cfe569",
   "metadata": {},
   "source": [
    "See how we have to go into the second tensor of the 2nd training example? The second part should be combined, so we do that\n",
    "(looked up at [Antimatter543/karpathy-NN-lectures](https://github.com/Antimatter543/karpathy-NN-lectures/blob/main/2%20-%20makemore/vid_exercises.ipynb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2cc4b041-c8cf-49e9-a12b-94ce4f4b3d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc[1][1][stoi['m']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9b24b-fe8e-4186-9c8c-9f61e3bb8ed1",
   "metadata": {},
   "source": [
    "4 is because our example has 4 length â€” 1 less than bigrams for the same word (emma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "09fbf347-dfda-47b5-a959-1a05e33a2b9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 54])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xenc = xenc.reshape(4, -1).float()\n",
    "xenc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a1e9115-7aff-4845-9ccc-f27e5522d297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fd9b41e5d20>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xenc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "16c83fd3-f46b-4d9d-9717-3957e6158bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494ddb45-4d71-4d9f-92c0-7ae91cd1c172",
   "metadata": {},
   "source": [
    "Manual forward pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "77fcb1dd-a471-4ed8-89b3-cf65adf91e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.9894299507141113"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = xenc @ W\n",
    "counts = logits.exp()\n",
    "probs = counts / counts.sum(1, keepdims=True)\n",
    "loss = -probs[torch.arange(4), ys].log().mean()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8fd792e1-1b48-4178-999e-3ab72c9c7acb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W.grad = None\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0c3237b-2d3f-4037-a2f7-cd863e38d55c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W.data += -0.1 * W.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "00773e24-4e4d-4ef3-9758-57e581cf79b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.042260646820068\n"
     ]
    }
   ],
   "source": [
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9db9848-ca0d-498e-a5fc-0aa90f39dca3",
   "metadata": {},
   "source": [
    "Loss is improving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d09ff5-0d9d-4d01-9779-c796c4a3cb74",
   "metadata": {},
   "source": [
    "Let's put everything together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab8fbd1a-0b6d-4e98-85b6-de9049b863a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xs, ys = [], []\n",
    "\n",
    "for w in words:\n",
    "  chs = ['.'] + list(w) + ['.']\n",
    "  for ch1, ch2, ch3 in zip(chs, chs[1:], chs[2:]):\n",
    "    xs.append((stoi[ch1], stoi[ch2]))\n",
    "    ys.append(stoi[ch3])\n",
    "    \n",
    "xs = torch.tensor(xs)\n",
    "ys = torch.tensor(ys)\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "W = torch.randn((27*2, 27), generator=g, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ebf863ce-aec0-4404-a516-e5c0108c7148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.186271667480469\n",
      "3.3573689460754395\n",
      "3.042151689529419\n",
      "2.871455430984497\n",
      "2.7671947479248047\n",
      "2.6946818828582764\n",
      "2.6390926837921143\n",
      "2.5949816703796387\n",
      "2.559002637863159\n",
      "2.529222011566162\n",
      "2.5042335987091064\n",
      "2.483072519302368\n",
      "2.464961051940918\n",
      "2.4493141174316406\n",
      "2.4356541633605957\n",
      "2.423619031906128\n",
      "2.412919759750366\n",
      "2.4033381938934326\n",
      "2.394700288772583\n",
      "2.386871099472046\n",
      "2.379739999771118\n",
      "2.3732175827026367\n",
      "2.3672289848327637\n",
      "2.3617119789123535\n",
      "2.3566133975982666\n",
      "2.3518879413604736\n",
      "2.34749698638916\n",
      "2.343406915664673\n",
      "2.3395884037017822\n",
      "2.3360161781311035\n",
      "2.332667589187622\n",
      "2.3295230865478516\n",
      "2.3265652656555176\n",
      "2.3237788677215576\n",
      "2.3211495876312256\n",
      "2.3186655044555664\n",
      "2.3163154125213623\n",
      "2.314089059829712\n",
      "2.3119773864746094\n",
      "2.3099725246429443\n",
      "2.3080661296844482\n",
      "2.3062520027160645\n",
      "2.3045237064361572\n",
      "2.302875518798828\n",
      "2.301301956176758\n",
      "2.2997987270355225\n",
      "2.298360824584961\n",
      "2.2969841957092285\n",
      "2.2956652641296387\n",
      "2.294400691986084\n",
      "2.293187141418457\n",
      "2.2920210361480713\n",
      "2.290900468826294\n",
      "2.2898223400115967\n",
      "2.2887845039367676\n",
      "2.2877843379974365\n",
      "2.28682017326355\n",
      "2.2858901023864746\n",
      "2.284992218017578\n",
      "2.2841250896453857\n",
      "2.2832870483398438\n",
      "2.2824764251708984\n",
      "2.281691551208496\n",
      "2.2809317111968994\n",
      "2.280195951461792\n",
      "2.27948260307312\n",
      "2.2787911891937256\n",
      "2.2781198024749756\n",
      "2.27746844291687\n",
      "2.2768354415893555\n",
      "2.2762207984924316\n",
      "2.275623083114624\n",
      "2.2750420570373535\n",
      "2.2744765281677246\n",
      "2.273926258087158\n",
      "2.273390769958496\n",
      "2.2728688716888428\n",
      "2.2723608016967773\n",
      "2.2718653678894043\n",
      "2.2713818550109863\n",
      "2.2709107398986816\n",
      "2.270451068878174\n",
      "2.2700023651123047\n",
      "2.269564390182495\n",
      "2.269136667251587\n",
      "2.2687184810638428\n",
      "2.268310308456421\n",
      "2.267910957336426\n",
      "2.2675209045410156\n",
      "2.267138957977295\n",
      "2.26676607131958\n",
      "2.2664008140563965\n",
      "2.266043186187744\n",
      "2.265693426132202\n",
      "2.2653510570526123\n",
      "2.2650156021118164\n",
      "2.2646865844726562\n",
      "2.264364719390869\n",
      "2.2640492916107178\n",
      "2.263740062713623\n"
     ]
    }
   ],
   "source": [
    "for k in range(100):\n",
    "  xenc = F.one_hot(xs, num_classes=27)\n",
    "  xenc = xenc.reshape(len(xenc), -1).float()\n",
    "\n",
    "  logits = xenc @ W\n",
    "  counts = logits.exp()\n",
    "  probs = counts / counts.sum(1, keepdims=True)\n",
    "  loss = -probs[torch.arange(len(xenc)), ys].log().mean()\n",
    "  \n",
    "  print(loss.item())\n",
    "  \n",
    "  W.grad = None\n",
    "  loss.backward()\n",
    "\n",
    "  W.data += -50 * W.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fba322f-10d9-452b-9a9a-48990ab5d7cf",
   "metadata": {},
   "source": [
    "Seems like loss is a bit lower than bigram but not as low as count method ðŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac382117-20e6-4d69-ac87-1cd3f068a0a2",
   "metadata": {},
   "source": [
    "Sampling from net:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17ceaf0e-0e25-4c85-a5be-075918e54ad4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aunide.\n",
      "aliasad.\n",
      "ushfay.\n",
      "ainn.\n",
      "aui.\n",
      "ritoleras.\n",
      "get.\n",
      "adannaauranileniassibdainrwi.\n",
      "ol.\n",
      "seisiely.\n"
     ]
    }
   ],
   "source": [
    "# finally, sample from the 'neural net' model\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(10):\n",
    "  \n",
    "  out = []\n",
    "  ix1, ix2 = 0, 0\n",
    "  while True:\n",
    "    xenc = F.one_hot(torch.tensor([ix1, ix2]), num_classes=27).float()\n",
    "    xenc = xenc.reshape((1, -1))\n",
    "    logits = xenc @ W\n",
    "    counts = logits.exp()\n",
    "    probs = counts / counts.sum(1, keepdims=True)\n",
    "    \n",
    "    ix1 = ix2\n",
    "    ix2 = torch.multinomial(probs, num_samples=1, replacement=True, generator=g).item()\n",
    "    out.append(itos[ix2])\n",
    "    if ix2 == 0:\n",
    "      break\n",
    "  print(''.join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef10058-bd77-4130-a1a7-da3c43a61a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
